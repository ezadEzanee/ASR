{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPZxERUrBPW1rFQQv3gcv5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezadEzanee/ASR/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2VS181e1i4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6c7e7d-7244-4de4-d711-57cfca61417d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ pip -q install virtualenv\n",
            "$ python -m virtualenv /content/venv\n",
            "$ /content/venv/bin/pip -q install --upgrade pip\n",
            "Using venv: /content/venv\n",
            "Site-packages: /content/venv/lib/python3.12/site-packages\n",
            "Python in venv: Python 3.12.11\n"
          ]
        }
      ],
      "source": [
        "# Create /content/venv reliably (fallback to virtualenv if needed) and ensure pip exists.\n",
        "import os, subprocess, sys, pathlib\n",
        "\n",
        "VENV_DIR = \"/content/venv\"\n",
        "\n",
        "def run(cmd):\n",
        "    print(\"$\", cmd)\n",
        "    rc = subprocess.call(cmd, shell=True)\n",
        "    if rc != 0:\n",
        "        raise SystemExit(rc)\n",
        "\n",
        "if not os.path.exists(VENV_DIR):\n",
        "    # Try stdlib venv first\n",
        "    rc = subprocess.call(f\"python -m venv {VENV_DIR}\", shell=True)\n",
        "    if rc != 0:\n",
        "        # Fallback to virtualenv\n",
        "        run(\"pip -q install virtualenv\")\n",
        "        run(f\"python -m virtualenv {VENV_DIR}\")\n",
        "\n",
        "# Ensure pip inside venv (some Colab images miss ensurepip)\n",
        "pip_path = f\"{VENV_DIR}/bin/pip\"\n",
        "py_path  = f\"{VENV_DIR}/bin/python\"\n",
        "if not os.path.exists(pip_path):\n",
        "    run(\"wget -q https://bootstrap.pypa.io/get-pip.py -O /tmp/get-pip.py\")\n",
        "    run(f\"{py_path} /tmp/get-pip.py\")\n",
        "\n",
        "# Upgrade pip\n",
        "run(f\"{pip_path} -q install --upgrade pip\")\n",
        "\n",
        "# Make this notebook import from the venv first\n",
        "venv_site = next(pathlib.Path(f\"{VENV_DIR}/lib\").glob(\"python*/site-packages\"))\n",
        "if str(venv_site) not in sys.path:\n",
        "    sys.path.insert(0, str(venv_site))\n",
        "os.environ[\"VIRTUAL_ENV\"] = VENV_DIR\n",
        "os.environ[\"PYTHONNOUSERSITE\"] = \"1\"   # ignore user site-packages\n",
        "\n",
        "print(\"Using venv:\", VENV_DIR)\n",
        "print(\"Site-packages:\", venv_site)\n",
        "print(\"Python in venv:\", subprocess.check_output([py_path, \"-V\"]).decode().strip())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess\n",
        "\n",
        "VENV_DIR = \"/content/venv\"\n",
        "pip = f\"{VENV_DIR}/bin/pip\"\n",
        "\n",
        "# Pins that play nice with pyannote + torch\n",
        "subprocess.check_call([pip, \"install\", \"-q\", \"pandas==2.2.3\", \"numpy==2.2.6\"])\n",
        "\n",
        "# Torch/torchaudio: try CUDA 12.1 → 11.8 → CPU wheels\n",
        "rc = os.system(f\"{pip} -q install torch torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
        "if rc != 0:\n",
        "    rc = os.system(f\"{pip} -q install torch torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
        "    if rc != 0:\n",
        "        os.system(f\"{pip} -q install torch torchaudio\")\n",
        "\n",
        "# ASR + diarization\n",
        "subprocess.check_call([pip, \"install\", \"-q\", \"faster-whisper\", \"ctranslate2\", \"pyannote.audio==3.1.1\"])\n",
        "\n",
        "# Verify versions (importing from venv thanks to Cell 1)\n",
        "import numpy, pandas, torch, torchaudio\n",
        "print(\"numpy     :\", numpy.__version__, numpy.__file__)\n",
        "print(\"pandas    :\", pandas.__version__, pandas.__file__)\n",
        "print(\"torch     :\", torch.__version__)\n",
        "print(\"torchaudio:\", torchaudio.__version__)\n"
      ],
      "metadata": {
        "id": "kCZKeIRj3Jv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52855432-19ed-4d15-9da3-b378306c9f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy     : 2.0.2 /usr/local/lib/python3.12/dist-packages/numpy/__init__.py\n",
            "pandas    : 2.2.3 /content/venv/lib/python3.12/site-packages/pandas/__init__.py\n",
            "torch     : 2.5.1+cu121\n",
            "torchaudio: 2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive if your file is there\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "\n",
        "# ---- INPUT ----\n",
        "INPUT_MP4 = \"/content/drive/MyDrive/ASR/Process Walkthrough Session #2 part1.mp4\"   # <-- change this to your file path\n",
        "\n",
        "# ---- Transcription settings ----\n",
        "MODEL_ID   = \"large-v3\"       # or \"medium\" if you want faster\n",
        "FORCE_LANG = None             # \"en\" to force English, None for auto\n",
        "TRANSLATE  = True            # True to translate Malay/English → English\n",
        "\n",
        "# ---- Diarization settings ----\n",
        "PYANNOTE_MODEL = \"pyannote/speaker-diarization-3.1\"\n",
        "\n",
        "# Pull HF token from Colab secret environment\n",
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')\n",
        "\n",
        "HF_TOKEN = userdata.get(\"HF_TOKEN\")   # ✅ secure, no hardcoding\n",
        "\n",
        "NUM_SPEAKERS = None           # e.g., 3 to force exactly 3\n",
        "MIN_SPEAKERS = None           # used only if NUM_SPEAKERS is None\n",
        "MAX_SPEAKERS = None\n",
        "\n",
        "# Domain prompt to bias ASR (optional)\n",
        "DOMAIN_PROMPT = (\n",
        "    \"Oracle E-Business Suite, Discrete Manufacturing, BOM, WIP, subinventory, \"\n",
        "    \"AHP, AAVE, AERP, standard cost, machine rate, labor rate, overhead, work order, \"\n",
        "    \"job completion, MU18, Order Management, delivery order, UAT, CRP.\"\n",
        ")\n",
        "\n",
        "print(\"✅ Settings loaded. HF_TOKEN found?\", bool(HF_TOKEN))"
      ],
      "metadata": {
        "id": "IAkMb1pk3RDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "dfb2187f-7ab3-44a2-f1d5-793887500c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1147158165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Drive if your file is there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, tempfile, subprocess\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def ts(): return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "def step_start(i,n,msg): print(f\"[{i}/{n}] {msg} (start {ts()})\"); return time.perf_counter()\n",
        "def step_end(i,n,t0,extra=None): dt=time.perf_counter()-t0; print(f\"[{i}/{n}] end {ts()} ({dt:.1f}s){' | '+extra if extra else ''}\")\n",
        "def srt_time(s):\n",
        "    if s < 0: s = 0\n",
        "    return str(timedelta(seconds=s))[:-3].replace('.', ',')\n",
        "def vtt_time(s):\n",
        "    if s < 0: s = 0\n",
        "    return str(timedelta(seconds=s))[:-3]\n",
        "\n",
        "assert os.path.exists(INPUT_MP4), f\"Input not found: {INPUT_MP4}\"\n",
        "base, _ = os.path.splitext(INPUT_MP4)\n",
        "p2 = base + \" - Process 2.json\"\n",
        "p3 = base + \" - Process 3.json\"\n",
        "t4 = base + \" - Process 4.txt\"\n",
        "s4 = base + \" - Process 4.srt\"\n",
        "v4 = base + \" - Process 4.vtt\"\n",
        "\n",
        "# ---------- Process 2 ----------\n",
        "t0 = step_start(2,4,\"Transcribing with faster-whisper\")\n",
        "from faster_whisper import WhisperModel\n",
        "import torch\n",
        "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "compute = \"float16\" if device==\"cuda\" else \"int8\"\n",
        "task    = \"translate\" if TRANSLATE else \"transcribe\"\n",
        "\n",
        "if not os.path.exists(p2):\n",
        "    wmodel = WhisperModel(MODEL_ID, device=device, compute_type=compute)\n",
        "    seg_iter, info = wmodel.transcribe(\n",
        "        INPUT_MP4,\n",
        "        language=FORCE_LANG,\n",
        "        task=task,\n",
        "        beam_size=5,\n",
        "        vad_filter=True,\n",
        "        vad_parameters=dict(min_speech_duration_ms=300),\n",
        "        initial_prompt=DOMAIN_PROMPT,\n",
        "        condition_on_previous_text=True,\n",
        "    )\n",
        "    segs = [{\"start\": float(s.start), \"end\": float(s.end), \"text\": s.text.strip()} for s in seg_iter]\n",
        "    lang = getattr(info, \"language\", None) or FORCE_LANG or \"unknown\"\n",
        "    with open(p2, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"lang\": lang, \"segments\": segs}, f, ensure_ascii=False, indent=2)\n",
        "    step_end(2,4,t0,f\"cache -> {p2}\")\n",
        "else:\n",
        "    with open(p2, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    segs, lang = data[\"segments\"], data[\"lang\"]\n",
        "    step_end(2,4,t0,\"loaded cache\")\n",
        "\n",
        "# ---------- Process 3 ----------\n",
        "t1 = step_start(3,4,\"Running diarization\")\n",
        "diar = None\n",
        "if os.path.exists(p3):\n",
        "    with open(p3, \"r\", encoding=\"utf-8\") as f:\n",
        "        diar = json.load(f)\n",
        "    step_end(3,4,t1,\"loaded cache\")\n",
        "else:\n",
        "    if not HF_TOKEN:\n",
        "        step_end(3,4,t1,\"skipped (no HF token)\")\n",
        "    else:\n",
        "        # Extract mono/16k wav\n",
        "        tmp_wav = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
        "        subprocess.run([\"ffmpeg\", \"-y\", \"-i\", INPUT_MP4, \"-ar\", \"16000\", \"-ac\", \"1\", tmp_wav], check=True)\n",
        "        try:\n",
        "            from pyannote.audio import Pipeline\n",
        "            pipeline = Pipeline.from_pretrained(PYANNOTE_MODEL, use_auth_token=HF_TOKEN)\n",
        "        except Exception as e:\n",
        "            print(f\"[Diarization] Init failed: {e}\")\n",
        "            pipeline = None\n",
        "        if pipeline is not None:\n",
        "            kwargs = {}\n",
        "            if NUM_SPEAKERS is not None:\n",
        "                kwargs[\"num_speakers\"] = NUM_SPEAKERS\n",
        "            else:\n",
        "                if MIN_SPEAKERS is not None: kwargs[\"min_speakers\"] = MIN_SPEAKERS\n",
        "                if MAX_SPEAKERS is not None: kwargs[\"max_speakers\"] = MAX_SPEAKERS\n",
        "            ann = pipeline({\"audio\": tmp_wav}, **kwargs) if kwargs else pipeline({\"audio\": tmp_wav})\n",
        "            diar = [{\"start\": float(t.start), \"end\": float(t.end), \"speaker\": spk}\n",
        "                    for t,_,spk in ann.itertracks(yield_label=True)]\n",
        "            with open(p3, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(diar, f, ensure_ascii=False, indent=2)\n",
        "            step_end(3,4,t1,f\"cache -> {p3}\")\n",
        "        else:\n",
        "            step_end(3,4,t1,\"skipped\")\n",
        "\n",
        "# ---------- Process 4 ----------\n",
        "t2 = step_start(4,4,\"Merging segments + diarization\")\n",
        "\n",
        "def best_speaker(seg_start, seg_end, diar_list):\n",
        "    best, ov = \"SPEAKER\", 0.0\n",
        "    if not diar_list: return best\n",
        "    for d in diar_list:\n",
        "        s,e = float(d[\"start\"]), float(d[\"end\"])\n",
        "        left, right = max(seg_start,s), min(seg_end,e)\n",
        "        overlap = max(0.0, right-left)\n",
        "        if overlap > ov:\n",
        "            ov, best = overlap, d[\"speaker\"]\n",
        "    return best\n",
        "\n",
        "for seg in segs:\n",
        "    seg[\"speaker\"] = best_speaker(seg[\"start\"], seg[\"end\"], diar)\n",
        "\n",
        "with open(t4, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"[Language: {lang}]\\n\\n\")\n",
        "    for seg in segs:\n",
        "        hhmmss = str(timedelta(seconds=int(seg[\"start\"])))\n",
        "        f.write(f\"[{hhmmss}] {seg['speaker']}: {seg['text']}\\n\")\n",
        "\n",
        "with open(s4, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, seg in enumerate(segs, 1):\n",
        "        f.write(f\"{i}\\n\")\n",
        "        f.write(f\"{srt_time(seg['start'])} --> {srt_time(seg['end'])}\\n\")\n",
        "        f.write(f\"{seg['speaker']}: {seg['text']}\\n\\n\")\n",
        "\n",
        "with open(v4, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"WEBVTT\\n\\n\")\n",
        "    for seg in segs:\n",
        "        f.write(f\"{vtt_time(seg['start'])} --> {vtt_time(seg['end'])}\\n\")\n",
        "        f.write(f\"{seg['speaker']}: {seg['text']}\\n\\n\")\n",
        "\n",
        "step_end(4,4,t2)\n",
        "\n",
        "print(\"\\n=== Outputs ===\")\n",
        "print(\"Text:\", t4)\n",
        "print(\"SRT :\", s4)\n",
        "print(\"VTT :\", v4)\n",
        "\n"
      ],
      "metadata": {
        "id": "Kr35PgM63cdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-tsCxwv3ede"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}